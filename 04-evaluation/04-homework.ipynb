{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this homework, we will use the **lead scoring Bank Marketing** dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-10-15 16:09:23--  https://raw.githubusercontent.com/alexeygrigorev/datasets/master/course_lead_scoring.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 OK\n",
      "Length: 80876 (79K) [text/plain]\n",
      "Saving to: ‘course_lead_scoring.csv’\n",
      "\n",
      "course_lead_scoring 100%[===================>]  78.98K  --.-KB/s    in 0.005s  \n",
      "\n",
      "2025-10-15 16:09:23 (16.4 MB/s) - ‘course_lead_scoring.csv’ saved [80876/80876]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/alexeygrigorev/datasets/master/course_lead_scoring.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this dataset our desired target for classification task will be `converted` variable - has the client signed up to the platform or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lead_source</th>\n",
       "      <th>industry</th>\n",
       "      <th>number_of_courses_viewed</th>\n",
       "      <th>annual_income</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>location</th>\n",
       "      <th>interaction_count</th>\n",
       "      <th>lead_score</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>paid_ads</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>79450.0</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>south_america</td>\n",
       "      <td>4</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>social_media</td>\n",
       "      <td>retail</td>\n",
       "      <td>1</td>\n",
       "      <td>46992.0</td>\n",
       "      <td>employed</td>\n",
       "      <td>south_america</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>events</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>5</td>\n",
       "      <td>78796.0</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>australia</td>\n",
       "      <td>3</td>\n",
       "      <td>0.69</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>paid_ads</td>\n",
       "      <td>retail</td>\n",
       "      <td>2</td>\n",
       "      <td>83843.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>australia</td>\n",
       "      <td>1</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>referral</td>\n",
       "      <td>education</td>\n",
       "      <td>3</td>\n",
       "      <td>85012.0</td>\n",
       "      <td>self_employed</td>\n",
       "      <td>europe</td>\n",
       "      <td>3</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    lead_source    industry  number_of_courses_viewed  annual_income  \\\n",
       "0      paid_ads         NaN                         1        79450.0   \n",
       "1  social_media      retail                         1        46992.0   \n",
       "2        events  healthcare                         5        78796.0   \n",
       "3      paid_ads      retail                         2        83843.0   \n",
       "4      referral   education                         3        85012.0   \n",
       "\n",
       "  employment_status       location  interaction_count  lead_score  converted  \n",
       "0        unemployed  south_america                  4        0.94          1  \n",
       "1          employed  south_america                  1        0.80          0  \n",
       "2        unemployed      australia                  3        0.69          1  \n",
       "3               NaN      australia                  1        0.87          0  \n",
       "4     self_employed         europe                  3        0.62          1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leading_score = pd.read_csv(\"course_lead_scoring.csv\")\n",
    "leading_score.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Check if the missing values are presented in the features.\n",
    "\n",
    "- If there are missing values:\n",
    "    - For caterogiral features, replace them with `NA`\n",
    "\n",
    "    - For numerical features, replace with with `0.0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lead_source                 128\n",
       "industry                    134\n",
       "number_of_courses_viewed      0\n",
       "annual_income               181\n",
       "employment_status           100\n",
       "location                     63\n",
       "interaction_count             0\n",
       "lead_score                    0\n",
       "converted                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values\n",
    "leading_score.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values for categorical and numerical features\n",
    "for col in leading_score.columns:\n",
    "    if leading_score[col].dtype == 'object':\n",
    "        leading_score[col] = leading_score[col].fillna('NA')\n",
    "    else:\n",
    "        leading_score[col] = leading_score[col].fillna(0.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into 3 parts: train/validation/test with 60%/20%/20% distribution. Use `train_test_split` function for that with `random_state=1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "df_full_train, df_test = train_test_split(leading_score, test_size=0.2, random_state=1)\n",
    "df_train, df_val = train_test_split(df_full_train, test_size=0.25, random_state=1)\n",
    "\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_val = df_val.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "\n",
    "y_train = df_train.converted.values\n",
    "y_val = df_val.converted.values\n",
    "y_test = df_test.converted.values\n",
    "\n",
    "del df_train['converted']\n",
    "del df_val['converted']\n",
    "del df_test['converted']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: ROC AUC feature importance "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC AUC could also be used to evaluate feature importance of numerical variables.\n",
    "\n",
    "- For each numerical variable, use it as score (aka prediction) and compute the AUC with the `y` variable as ground truth.\n",
    "\n",
    "- Use the training dataset for that\n",
    "\n",
    "If your AUC is < 0.5, invert this variable by putting \"-\" in front (e.g. `-df_train['balance']`)\n",
    "\n",
    "AUC can go below 0.5 if the variable is negatively correlated with the target variable. You can change the direction of the correlation by negating this variable - then negative correlation becomes positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'number_of_courses_viewed': 0.764,\n",
       " 'interaction_count': 0.738,\n",
       " 'lead_score': 0.614,\n",
       " 'annual_income': 0.552}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Select only numerical features\n",
    "num_features = df_train.select_dtypes(include=['number']).columns.tolist()\n",
    "\n",
    "auc_scores = {}\n",
    "\n",
    "for feature in num_features:\n",
    "    score = roc_auc_score(y_train, df_train[feature])\n",
    "    \n",
    "    # If AUC < 0.5, invert the feature\n",
    "    if score < 0.5:\n",
    "        score = roc_auc_score(y_train, -df_train[feature])\n",
    "    \n",
    "    auc_scores[feature] = round(score, 3)\n",
    "\n",
    "# Sort descending by AUC\n",
    "sorted_auc = dict(sorted(auc_scores.items(), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "sorted_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which numerical variable (among the following 4) has the highest AUC? **`number_of_courses_viewed`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: Training the model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply one-hot-encoding using `DictVectorizer` and train the logistic regression with these parameters:\n",
    "\n",
    "```python\n",
    "LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the AUC of this model on the validation dataset? (round to 3 digits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3: Precision and Recall "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's compute precision and recall for our model.\n",
    "\n",
    "* Evaluate the model on all thresholds from `0.0` to `1.0` with step `0.01`\n",
    "\n",
    "* For each threshold, compute precision and recall\n",
    "\n",
    "* Plot them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At which threshold precision and recall curves intersect?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4: F1 score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision and recall are conflicting - when one grows, the other goes down. That's why they are often combined into the F1 score - a metrics that takes into account both\n",
    "\n",
    "This is the formula for computing F1:\n",
    "\n",
    "$$F_1 = 2 \\cdot \\cfrac{P \\cdot R}{P + R}$$\n",
    "\n",
    "Where $P$ is precision and $R$ is recall.\n",
    "\n",
    "Let's compute F1 for all thresholds from 0.0 to 1.0 with increment 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At which threshold F1 is maximal?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5: 5-Fold CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `KFold` class from Scikit-Learn to evaluate our model on 5 different folds:\n",
    "\n",
    "```python\n",
    "KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "```\n",
    "\n",
    "* Iterate over different folds of `df_full_train`\n",
    "\n",
    "* Split the data into train and validation\n",
    "\n",
    "* Train the model on train with these parameters: `LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)`\n",
    "\n",
    "* Use AUC to evaluate the model on validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How large is standard deviation of the scores across different folds?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6: Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use 5-Fold cross-validation to find the best parameter `C`\n",
    "\n",
    "* Iterate over the following `C` values: `[0.000001, 0.001, 1]`\n",
    "\n",
    "* Initialize `KFold` with the same parameters as previously\n",
    "\n",
    "* Use these parameters for the model: `LogisticRegression(solver='liblinear', C=C, max_iter=1000)`\n",
    "\n",
    "* Compute the mean score as well as the std (round the mean and std to 3 decimal digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which `C` leads to the best mean score?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
